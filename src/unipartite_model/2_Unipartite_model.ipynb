{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94bf4bee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### DLS Project - Recommendation System using GNN\n",
    "\n",
    "1. Unipartite Model\n",
    "2. Sample Script to run and test on smaller sample size\n",
    "3. The Final_script_users_model.py file is executed on HPC System with a larger sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd28c3c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611f28b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "# PyG\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "PATH_INPUT = '/N/project/APRS'\n",
    "PATH_OUTPUT = '/N/project/APRS/model_user_results/iter4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c9c31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Processing the merged dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0de818",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Reading the maerged dataset'\n",
    "data_df = pd.read_pickle(os.path.join(PATH_INPUT,'2_mergedData_final.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843d178c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Removing all records with overall rating less than 3'\n",
    "# For recommendation we want to keep only books of high ratings\n",
    "\n",
    "data_df_3 = data_df[data_df['overall']>=3]\n",
    "data_df_3.to_pickle(os.path.join(PATH_INPUT,'merged_data_greater3_rating.pkl'))\n",
    "del data_df # remove to save memory\n",
    "\n",
    "# saved to stop reading from large file\n",
    "#data_df_3 = pd.read_pickle(os.path.join(PATH_INPUT,'merged_data_greater3_rating.pkl'))\n",
    "#print(f\"length of dataframe : {len(data_df_3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760b67d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Sample only those users with minimum 5 transactions so that we have some user history'\n",
    "sample_users = data_df_3.groupby('reviewerID')['asin'].count().reset_index(drop=False)\n",
    "sample_users['buy_frequency'] = sample_users['asin'].apply(lambda x: 1 if x >=5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6774c29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7618401\n"
     ]
    }
   ],
   "source": [
    "'Filter Dataset'\n",
    "data_df_3_freq = data_df_3.merge(sample_users, on ='reviewerID', suffixes=('_left', '_right'))\n",
    "data_df_3_freq =  data_df_3_freq[data_df_3_freq.buy_frequency == 1] # only with 5 or more \n",
    "print(len(data_df_3_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46e942e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685656"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Sampling the dataset as the records are in millions'\n",
    "data_df_3_freq = data_df_3_freq.rename(columns ={\"asin_left\": \"asin\"})\n",
    "data_df_3_sample = data_df_3_freq.sample(frac=.09) # change this in py file for larger sample\n",
    "len(data_df_3_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789c33ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Creating label encoders for asin and revieweID as they are alphanumeric'\n",
    "le_user = pp.LabelEncoder()\n",
    "le_item = pp.LabelEncoder()\n",
    "data_df_3_sample['user_id_idx'] = le_user.fit_transform(data_df_3_sample['reviewerID'].values)\n",
    "data_df_3_sample['item_id_idx'] = le_item.fit_transform(data_df_3_sample['asin'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87db6c94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18244/106948215.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_df_3_sample['price'] = data_df_3_sample['price'].str.replace(\"$\",'')\n"
     ]
    }
   ],
   "source": [
    "'The price column is needed for splitting the users based on max dollar purchases'\n",
    "data_df_3_sample['price'] = data_df_3_sample['price'].str.replace(\"$\",'')\n",
    "data_df_3_sample['price'] = pd.to_numeric(data_df_3_sample['price'],errors='coerce')\n",
    "data_df_3_sample['price'] = data_df_3_sample['price'].fillna(0)\n",
    "\n",
    "data_df_Price_grouping = data_df_3_sample.groupby('reviewerID')['price'].max()\n",
    "data_df_Price_grouping = data_df_Price_grouping.reset_index(drop=False)\n",
    "data_df_Price_grouping[\"price_category\"] = pd.cut(\n",
    "        x=data_df_Price_grouping[\"price\"],\n",
    "        bins=[-1, 25, 50, 100, 10000], #Categories\n",
    "        labels=[0, 1, 2, 3],)\n",
    "data_df_Price_grouping[\"price_category\"] = data_df_Price_grouping[\"price_category\"].fillna(0)\n",
    "data_df_3_sample = data_df_3_sample.merge(data_df_Price_grouping, on ='reviewerID', suffixes=('_left', '_right'))\n",
    "# this will be added as an attribute to the network nodes\n",
    "nodes_attr = data_df_Price_grouping.set_index('reviewerID').to_dict(orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5c9790",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    290330\n",
       "1     26613\n",
       "2      3412\n",
       "3      1158\n",
       "Name: price_category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Distribution of Price category'\n",
    "data_df_Price_grouping.price_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99177dca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Converting the dataset to a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d314410c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18244/2731727868.py:7: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
      "\n",
      "  print(nx.info(G))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 529577 nodes and 685169 edges\n"
     ]
    }
   ],
   "source": [
    "'Setting up the network'\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(data_df_3_sample['reviewerID'], bipartite='User') \n",
    "G.add_nodes_from(data_df_3_sample['item_id_idx'], bipartite='Item') \n",
    "G.add_weighted_edges_from(zip(data_df_3_sample['reviewerID'], \n",
    "                              data_df_3_sample['item_id_idx'], data_df_3_sample['overall']), weight = 'rating')\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebfcbf2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18244/3527936784.py:13: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
      "\n",
      "  print(nx.info(user_graph))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 321513 nodes and 7384424 edges\n"
     ]
    }
   ],
   "source": [
    "'Conversion to projection network with sum of ratings as weights (edge weight is ignored)'\n",
    "def my_weight(G, u, v, weight='rating'):\n",
    "    w = 0\n",
    "    for nbr in set(G[u]) & set(G[v]):         \n",
    "         w += G.edges[u,nbr].get(weight, 1) + G.edges[v, nbr].get(weight,1)        \n",
    "    return w\n",
    "\n",
    "user_nodes = [n for n in G.nodes() if G.nodes[n]['bipartite'] == 'User'] \n",
    "user_graph = bipartite.generic_weighted_projected_graph(G, nodes=user_nodes, weight_function=my_weight)\n",
    "nx.set_node_attributes(user_graph, nodes_attr) # price attribute added\n",
    "nodes_list = np.array(list(user_graph.nodes())) # list of nodes\n",
    "\n",
    "print(nx.info(user_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd233686",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'getting the edge index'\n",
    "for node in user_graph:\n",
    "    user_graph.nodes[node]['bipartite']=1\n",
    "user_pyg = from_networkx(user_graph)\n",
    "edge_index = user_pyg.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb092ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Conversion to PyG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13dfc366",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Node Features (degree centrality)'\n",
    "embeddings = np.array(list(dict(user_graph.degree()).values())) \n",
    "scale = StandardScaler()\n",
    "embeddings = scale.fit_transform(embeddings.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af95ad76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Classes created in the dataset based on price'\n",
    "labels = np.asarray([user_graph.nodes[i]['price_category'] for i in user_graph.nodes]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f26457f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Custom dataset'\n",
    "#reference - https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html\n",
    "class AmazonUsers(InMemoryDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super(AmazonUsers, self).__init__('.', transform, None, None)\n",
    "\n",
    "        data = Data(edge_index=edge_index)\n",
    "        \n",
    "        data.num_nodes = user_graph.number_of_nodes()\n",
    "        \n",
    "        # embedding \n",
    "        data.x = torch.from_numpy(embeddings).type(torch.float32)\n",
    "        \n",
    "        # labels\n",
    "        y = torch.from_numpy(labels).type(torch.long)\n",
    "        data.y = y.clone().detach()\n",
    "        \n",
    "        data.num_classes = 4\n",
    "\n",
    "        # splitting the data into train, validation and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(pd.Series(list(user_graph.nodes())), \n",
    "                                                            pd.Series(labels),\n",
    "                                                            test_size=0.30, \n",
    "                                                            random_state=42)\n",
    "        \n",
    "        n_nodes = user_graph.number_of_nodes()\n",
    "        \n",
    "        # create train and test masks for data\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[X_train.index] = True\n",
    "        test_mask[X_test.index] = True\n",
    "        data['train_mask'] = train_mask\n",
    "        data['test_mask'] = test_mask\n",
    "\n",
    "        self.data, self.slices = self.collate([data])\n",
    "\n",
    "    def _download(self):\n",
    "        return\n",
    "\n",
    "    def _process(self):\n",
    "        return\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n",
    "    \n",
    "dataset = AmazonUsers()\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12454a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Training the Graph Neural Network to get the embeddings of users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "935cbabf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 2)\n",
      "  (classifier): Linear(in_features=2, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'Graph Convolutional network to obtain user node embeddings'\n",
    "#reference: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(data.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = Linear(2, data.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = F.log_softmax(self.classifier(h), dim=1)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "311fe444",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'Model Training'\n",
    "model = GCN()\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  \n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  \n",
    "    out, h = model(data.x, data.edge_index)  \n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask]) # only training nodes\n",
    "    loss.backward()  \n",
    "    optimizer.step()  \n",
    "    return loss, h\n",
    "\n",
    "for epoch in range(201):\n",
    "    loss, h = train(data) # output loss and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ac0761",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "Train Accuracy: 0.9025055652073456\n",
      "Test Accuracy: 0.9041926721546022\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits,_ = model(data.x, data.edge_index)\n",
    "    mask1 = data['train_mask']\n",
    "    pred1 = logits[mask1].max(1)[1]\n",
    "    acc1 = pred1.eq(data.y[mask1]).sum().item() / mask1.sum().item()\n",
    "    mask = data['test_mask']\n",
    "    pred = logits[mask].max(1)[1]\n",
    "    acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "    return acc1,acc\n",
    "\n",
    "train_acc,test_acc = test()\n",
    "\n",
    "print('#' * 70)\n",
    "print('Train Accuracy: %s' %train_acc )\n",
    "print('Test Accuracy: %s' % test_acc)\n",
    "print('#' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d42161d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(PATH_OUTPUT, 'model_user_final.pkl'))\n",
    "embedding_vector = pd.DataFrame(h.detach().numpy())\n",
    "embedding_vector.to_csv(os.path.join(PATH_OUTPUT,'embedding_vector_user.csv'), index = False)\n",
    "data_df_3_sample.to_pickle(os.path.join(PATH_OUTPUT,'data_df_3_sample.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd1ff5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Finding Top K similar users and the books they bought as suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba5cdcfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewerID index in graph [4]\n"
     ]
    }
   ],
   "source": [
    "# Give a reviewer ID\n",
    "reviwerID_val = data_df_3_sample.reviewerID[10] # Example\n",
    "index = [i for i, x in enumerate(nodes_list) if reviwerID_val==x]\n",
    "print(f'reviewerID index in graph {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8939d595",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 neighbours of A3L79FRB5W2SCS :['A3L79FRB5W2SCS', 'A31LO2VFNAQIX', 'AUDUAV0IV70R7', 'A3V2E3T2VYF32L', 'AFMSUY9II8GXK']\n"
     ]
    }
   ],
   "source": [
    "k = 5 # of similar users\n",
    "distances = np.linalg.norm(h.detach().numpy() - h[index].detach().numpy(), axis = 1)\n",
    "# select indices of vectors having the lowest distances from the X\n",
    "neighbours = np.argpartition(distances, range(0, k))[:k]\n",
    "node_names = [nodes_list[i] for i in neighbours]\n",
    "print(f'Top {k} neighbours of {reviwerID_val} :{node_names}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1a20762",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10        0062412655\n",
      "75968     0062412655\n",
      "212595    0062412655\n",
      "504588    0062412655\n",
      "587224    0062412655\n",
      "Name: asin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'Printing the similar user purchases'\n",
    "# all books are 4 or 5 ratings\n",
    "similar_users_df = data_df_3_sample.loc[data_df_3_sample['reviewerID'].isin(node_names)]\n",
    "print(similar_users_df['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08265f37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>style</th>\n",
       "      <th>...</th>\n",
       "      <th>imageURL</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "      <th>details</th>\n",
       "      <th>categoryLast</th>\n",
       "      <th>asin_right</th>\n",
       "      <th>buy_frequency</th>\n",
       "      <th>user_id_idx</th>\n",
       "      <th>item_id_idx</th>\n",
       "      <th>price_right</th>\n",
       "      <th>price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75968</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 8, 2017</td>\n",
       "      <td>A31LO2VFNAQIX</td>\n",
       "      <td>0062412655</td>\n",
       "      <td>DAK</td>\n",
       "      <td>Love everything written by Beverly Jenkins. Ca...</td>\n",
       "      <td>Love everything written by Beverly Jenkins</td>\n",
       "      <td>1507420800</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>174015</td>\n",
       "      <td>7737</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 5, 2018</td>\n",
       "      <td>A3L79FRB5W2SCS</td>\n",
       "      <td>0062412655</td>\n",
       "      <td>Rene M. Mastin</td>\n",
       "      <td>Dreams are not just for the young, but for tho...</td>\n",
       "      <td>Dreams</td>\n",
       "      <td>1520208000</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>220168</td>\n",
       "      <td>7737</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504588</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 5, 2017</td>\n",
       "      <td>A3V2E3T2VYF32L</td>\n",
       "      <td>0062412655</td>\n",
       "      <td>Nirvana</td>\n",
       "      <td>This poignant story is heart wrenching. It wil...</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>1499212800</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>243415</td>\n",
       "      <td>7737</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587224</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 4, 2017</td>\n",
       "      <td>AFMSUY9II8GXK</td>\n",
       "      <td>0062412655</td>\n",
       "      <td>Paula</td>\n",
       "      <td>Loved it!!!  It's always like I'm coming home ...</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1499126400</td>\n",
       "      <td>{'Format:': ' Kindle Edition'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>273389</td>\n",
       "      <td>7737</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212595</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>07 22, 2017</td>\n",
       "      <td>AUDUAV0IV70R7</td>\n",
       "      <td>0062412655</td>\n",
       "      <td>Doris</td>\n",
       "      <td>I read it too quick, love this series, can not...</td>\n",
       "      <td>love this series</td>\n",
       "      <td>1500681600</td>\n",
       "      <td>{'Format:': ' Paperback'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>308231</td>\n",
       "      <td>7737</td>\n",
       "      <td>11.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall  verified   reviewTime      reviewerID        asin  \\\n",
       "75968       5.0      True   10 8, 2017   A31LO2VFNAQIX  0062412655   \n",
       "10          4.0      True   03 5, 2018  A3L79FRB5W2SCS  0062412655   \n",
       "504588      5.0      True   07 5, 2017  A3V2E3T2VYF32L  0062412655   \n",
       "587224      5.0      True   07 4, 2017   AFMSUY9II8GXK  0062412655   \n",
       "212595      5.0      True  07 22, 2017   AUDUAV0IV70R7  0062412655   \n",
       "\n",
       "          reviewerName                                         reviewText  \\\n",
       "75968              DAK  Love everything written by Beverly Jenkins. Ca...   \n",
       "10      Rene M. Mastin  Dreams are not just for the young, but for tho...   \n",
       "504588         Nirvana  This poignant story is heart wrenching. It wil...   \n",
       "587224           Paula  Loved it!!!  It's always like I'm coming home ...   \n",
       "212595           Doris  I read it too quick, love this series, can not...   \n",
       "\n",
       "                                           summary  unixReviewTime  \\\n",
       "75968   Love everything written by Beverly Jenkins      1507420800   \n",
       "10                                          Dreams      1520208000   \n",
       "504588                                     Amazing      1499212800   \n",
       "587224                                   Loved it!      1499126400   \n",
       "212595                            love this series      1500681600   \n",
       "\n",
       "                                 style  ... imageURL imageURLHighRes details  \\\n",
       "75968   {'Format:': ' Kindle Edition'}  ...       []              []     NaN   \n",
       "10      {'Format:': ' Kindle Edition'}  ...       []              []     NaN   \n",
       "504588  {'Format:': ' Kindle Edition'}  ...       []              []     NaN   \n",
       "587224  {'Format:': ' Kindle Edition'}  ...       []              []     NaN   \n",
       "212595       {'Format:': ' Paperback'}  ...       []              []     NaN   \n",
       "\n",
       "          categoryLast asin_right buy_frequency user_id_idx item_id_idx  \\\n",
       "75968    United States          6             1      174015        7737   \n",
       "10       United States         15             1      220168        7737   \n",
       "504588   United States          8             1      243415        7737   \n",
       "587224   United States          5             1      273389        7737   \n",
       "212595   United States          5             1      308231        7737   \n",
       "\n",
       "       price_right price_category  \n",
       "75968        11.99              0  \n",
       "10           11.99              0  \n",
       "504588       11.99              0  \n",
       "587224       11.99              0  \n",
       "212595       11.99              0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Simialr user book purchases'\n",
    "similar_users_df.sort_values('reviewerID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abhipy",
   "language": "python",
   "name": "abhipy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
